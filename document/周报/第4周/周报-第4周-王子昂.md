# 第4周周报——王子昂 #

## 数据处理 ##

* 文件编码格式转换：爬虫结果的表格为gbk编码，通过重新编码转换为utf-8

* 将csv中的每一行信息（标题+内容）保存为单独的txt文件，方便下一步的处理，共得到35687个txt文件

  ![1564835562577](周报-第4周-王子昂.assets/1564835562577.png)

* 对每一篇文章进行基本的数据清洗，去掉其中的html标签、字母、制表符、无用的符号，方便进行标注和命名实体识别

* 创建语料：对上一步清洗后的数据再进行分词、去停用词处理，将每篇文章的处理结果作为最终语料库中的一行，将生成的语料存储在`news_content_corpus.txt`中，最终共得到35687行

* 前三条文章处理结果如下图所示：

![1564804650676](周报-第4周-王子昂.assets/1564804650676.png)

## LDA主题提取 ##

* 对比了gensim、sklearn、lda三个包下的LDA模型

  * sklearn中的LDA模型基于变分推断EM算法
  * lda中的LDA模型基于Gibbs采样

* 基于困惑度确定主题数

  * 将语料库中的内容按照8:2划分为训练集和测试集

  * 将训练集和测试集的内容随机打乱

  * 选取至少出现过两次并且数量为前2000的词来生成文本表示向量

  * 用得到的向量生成器转化训练集和测试集

  * 利用sklearn中的LDA模型进行模型训练，主题数选取1~100以5为间隔，分别计算不同主题数下得到的LDA主题模型的困惑度，绘制主题数和困惑度的对应关系，如下图所示：

    ![1564751291519](周报-第4周-王子昂.assets/1564751291519.png)

    ![1564751478135](周报-第4周-王子昂.assets/1564751478135.png)

  * 选取可能的取值范围以更小的粒度进行分析

    ![1564802333358](周报-第4周-王子昂.assets/1564802333358.png)

  * 选取困惑度最小时的主题数（45）作为最终的主题数

* LDA模型训练：利用lda包下的LDA模型进行训练，选取主题数为45，迭代100次，将训练后的模型保存

* 获得每个主题的关键词

  * 得到LDA模型的主题——词分布
  * 获取每个主题下概率值最大的前20个词来代表该主题

  ![1564804555918](周报-第4周-王子昂.assets/1564804555918.png)

* 获得每个文档的主题

  * 得到LDA模型的文档——主题分布，下图为文档1，3，4，8，9的文档主题分布，可以看出大部分的文档主题的区分度还是较为明显的，但是对于部分文档，如文档1，有两个主题的概率较为接近，这种情况下主题的区分可能没有那么准去

    ![1564804469569](周报-第4周-王子昂.assets/1564804469569.png)

  * 选择可能性最大的主题作为文档的主题

  * 将每个文档对应的主题编号存储到csv中，格式为`[doc_id,topic_id]`

    ![1564835809924](周报-第4周-王子昂.assets/1564835809924.png)
  
  * 将主题提取的结果写回原始的`all_news_data.csv`文件，在最后加一列表示文档的主题，我们筛选了主题2的文档，通过主题词可知该类型的文档很可能和“保健品销售”有关，如下图所示：
  
    ![1564835980499](周报-第4周-王子昂.assets/1564835980499.png)
  
    从结果可以看出，分类的结果还是较为准确的。

## 命名实体识别 ##

### 数据标注 ###

* 对于进行了初步数据清洗的文档，随机抽取1000条进行标注
  * 最开始我们打算利用一个模型同时标记人名、机构名、时间、地点、食品安全专有名词，但这样的标记效率太低，我们尝试了一段时间就放弃了。
  * 后来我们利用已有的标记了人名、机构名、时间、地点的数据集，进行训练。因此只需要对文档中的食品安全专有名词进行标注，得到一个新的模型用来识别食品安全专有名词，提高了标记速度，但由于只有两个人标记，标注还是花费了很长的时间。
  * 后期有条件的话，希望能够动员更多人对数据进行标注，有望能进一步提高模型的准确率
* 使用YEDDA工具标记文档中的食品安全专有名词，如：保健食品、非洲猪瘟、五毛食品、明厨亮灶....

![1564815553063](周报-第4周-王子昂.assets/1564815553063.png)

* 采用BIO标注方式，标注好的样本如图所示：

  ![1564815760423](周报-第4周-王子昂.assets/1564815760423.png)

### 模型训练 ###

* 对于标记好的数据进行基本的清洗，由于标记的数据中存在对空格标记为O的现象，而直接训练会产生错误，利用正则表达式去掉这种情况

* 由于文档较长，对于标记好的数据，根据标点符号进行切分，将长文本转换为较短的文本，有助于提高训练的准确率

* 将切分好的数据按照 7:2:1 的比例划分为训练集、测试集、开发集，送入BiLSTM-CRF 模型进行训练，得到相应的模型

  食品安全专有名词模型训练日志如下：

  - 可以看到，f1得分最高只能达到66.83，效果并不是特别理想。我们猜想原因有以下几个：
    - 训练数据不够多。
    - 数据中的干扰项比较多，虽然进行过预处理，但是仍然存在一些特殊符号和数字英文乱码。
    - 非食品安全相关的数据较多，应该先进行文本分类，剔除与食品安全不相干的数据。
  - 后期有条件的话，希望能够动员更多人对数据进行标注，有望能进一步提高模型的准确率。

  ![foodNER-log](周报-第4周-王子昂.assets/foodNER-log.PNG)

* 获得标注好的人名、机构名、时间、地点数据集，送入BiLSTM-CRF 模型进行训练，得到相应的模型

  食品安全专有名词模型训练日志如下：

  ![otherNER-log](周报-第4周-王子昂.assets/otherNER-log.PNG)

### 测试结果 ###

#### 时间、地点、人名、组织名 ####

![otherNER](周报-第4周-王子昂.assets/otherNER.PNG)

#### 食品安全专有名词 ####

![foodNER](周报-第4周-王子昂.assets/foodNER.PNG)

## 向量化 ##

> 构建Word2Vec模型

* 利用数据处理中获得的语料，利用`word2vec.Text8Corpus`方法转化，作为模型的输入
* 设置词向量的维度为50，对Word2Vec模型进行训练
* 最后将得到的模型进行保存
* 测试结果如下

![1564804198684](周报-第4周-王子昂.assets/1564804198684.png)

## 下周需要完成的事情 ##

### 趋势分析 ###

* 阅读舆情趋势分析的相关论文，寻找可以利用的趋势分析的方法。
* 目前看到一篇关于基于马尔科夫链的舆情热度趋势分析的论文，利用回复量、评论量、转发量来量化热度，构造马尔可夫模型，最后对趋势进行预测。下周打算尝试这种方法，看看是否具备可行性。

